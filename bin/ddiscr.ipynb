{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import yaml\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn import metrics\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARN: OMP_NUM_THREADS=None =>\n",
      "... If you are using openblas if you are using openblas set OMP_NUM_THREADS=1 or risk subprocess calls hanging indefinitely\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yoyoteng/anaconda3/envs/py35/lib/python3.5/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os,sys\n",
    "root_path = os.path.dirname(os.path.dirname(os.path.abspath('run.py')))\n",
    "sys.path.append(root_path)\n",
    "\n",
    "from cfg import cfg\n",
    "from numerapi.numerapi import NumerAPI\n",
    "import models\n",
    "from data_utils import get_data_era_balanced,data_files,get_data, write_to_csv\n",
    "import opt\n",
    "\n",
    "model_list = [\n",
    "    ('aecgan',models.aec_gan.AecAdvModel,dict(istrain=False)),\n",
    "    ('aec',models.aec.AecModel,dict(istrain=False)),\n",
    "    ('xg',models.xg.XgModel,dict(istrain=False)),\n",
    "    ('aecganxg',models.aec_gan_xg.AecGanXgModel,dict(istrain=False)),# depends on model from AecAdvModel\n",
    "    #('aecgs',models.aec_gan_stack.AecAdvStackModel,dict(istrain=False)),\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'> <class 'pandas.core.series.Series'> <class 'pandas.core.series.Series'> <class 'pandas.core.series.Series'>\n",
      "(354192, 50) (354192,) (39421, 50) (39421,)\n"
     ]
    }
   ],
   "source": [
    "X_train,y_train,X_val,y_val = get_data_era_balanced(data_files[-1]['trainpath'])\n",
    "X_test,y_test,_,_,_=get_data(data_files[-1]['testpath'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "_X = np.concatenate([X_train,X_val,X_test],axis=0)\n",
    "_y = np.concatenate([[0]*X_train.shape[0],[0]*X_val.shape[0],[1]*X_test.shape[0]],axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import cross_validation as CV\n",
    "from sklearn.linear_model import LogisticRegression as LR\n",
    "from sklearn.ensemble import RandomForestClassifier as RF\n",
    "from sklearn.metrics import roc_auc_score as AUC\n",
    "from sklearn.metrics import accuracy_score as accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  3.1min finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    1.6s finished\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  3.1min finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    1.6s finished\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  3.1min finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    1.6s finished\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  3.1min finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    1.7s finished\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  3.0min finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    1.6s finished\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 15.6min finished\n"
     ]
    }
   ],
   "source": [
    "n_estimators = 100\n",
    "clf = RF( n_estimators = n_estimators, n_jobs = -1, verbose = True )\n",
    "scores = CV.cross_val_score( clf, _X, _y,scoring = 'roc_auc', cv = 5, verbose = 1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean AUC: 74.06%, std: 6.94% \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"mean AUC: {:.2%}, std: {:.2%} \\n\".format( scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 318649 samples, validate on 39421 samples\n",
      "Epoch 1/20\n",
      "318649/318649 [==============================] - 8s 27us/step - loss: 0.6739 - val_loss: 0.7205\n",
      "Epoch 2/20\n",
      "318649/318649 [==============================] - 8s 25us/step - loss: 0.6599 - val_loss: 0.7267\n",
      "Epoch 3/20\n",
      "318649/318649 [==============================] - 8s 25us/step - loss: 0.6545 - val_loss: 0.7255\n",
      "Epoch 4/20\n",
      "318649/318649 [==============================] - 8s 25us/step - loss: 0.6486 - val_loss: 0.7361\n",
      "Epoch 5/20\n",
      "318649/318649 [==============================] - 8s 26us/step - loss: 0.6444 - val_loss: 0.7392\n",
      "Epoch 6/20\n",
      "318649/318649 [==============================] - 8s 25us/step - loss: 0.6408 - val_loss: 0.7522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yoyoteng/anaconda3/envs/py35/lib/python3.5/site-packages/numpy/core/fromnumeric.py:57: FutureWarning: 'argmin' is deprecated. Use 'idxmin' instead. The behavior of 'argmin' will be corrected to return the positional minimum in the future. Use 'series.values.argmin' to get the position of the minimum now.\n",
      "  return getattr(obj, method)(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "clsf=models.datatype_discr.DDiscrModel()\n",
    "clsf.fit(X_train=X_train,y_train=y_train,X_validation=X_val,y_validation=y_val,X_test=X_test)\n",
    "clsf.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, Y, ids, eras, datatypes = get_data(data_files[-1]['trainpath'])\n",
    "Xt, Yt, idst, erast, datatypest = get_data(data_files[-1]['testpath'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred, _= clsf.predict(X)\n",
    "predt, _= clsf.predict(Xt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.median(pred),np.median(predt)\n",
    "\n",
    "#_=plt.hist(pred,label='trian')\n",
    "#_=plt.hist(predt,label='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "for era in sorted(list(np.unique(eras))):\n",
    "    inds = np.where(eras==era)\n",
    "    a=np.median(pred[inds])\n",
    "    plt.scatter(int(era.strip('era')),a)\n",
    "    \n",
    "for era in sorted(list(np.unique(erast))):\n",
    "    inds = np.where(erast==era)\n",
    "    a=np.median(predt[inds])\n",
    "    if era not in ['eraX']:\n",
    "        plt.scatter(int(era.strip('era')),a,color='black')\n",
    "    else:\n",
    "        plt.scatter(140,a,color='blue')\n",
    "        \n",
    "plt.figure(figsize=(10,5))\n",
    "plt.subplot(121)\n",
    "for era in sorted(list(np.unique(eras))):\n",
    "    inds = np.where(eras==era)\n",
    "    a=np.median(pred[inds])\n",
    "    plt.scatter(int(era.strip('era')),a)\n",
    "    \n",
    "for era in sorted(list(np.unique(erast))):\n",
    "    inds = np.where(erast==era)\n",
    "    a=np.median(predt[inds])\n",
    "    if era in ['eraX']:\n",
    "        continue\n",
    "    plt.scatter(int(era.strip('era')),a,color='black')\n",
    "plt.ylim(0.2,0.5)\n",
    "\n",
    "plt.subplot(122)\n",
    "vert_hist = np.histogram(pred, bins=100,density=True)\n",
    "plt.plot(vert_hist[0], vert_hist[1][:-1], '--',label='train',color='black')\n",
    "\n",
    "inds = np.where(erast!='eraX')\n",
    "vert_hist = np.histogram(predt[inds], bins=100,density=True)\n",
    "plt.plot(vert_hist[0], vert_hist[1][:-1], '--',label='validation',color='red')\n",
    "\n",
    "inds = np.where(erast!='eraX')\n",
    "vert_hist = np.histogram(predt[inds], bins=100,density=True)\n",
    "plt.plot(vert_hist[0], vert_hist[1][:-1], '-.',label='live',color='blue')\n",
    "plt.ylim(0.2,0.5)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py35]",
   "language": "python",
   "name": "conda-env-py35-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
